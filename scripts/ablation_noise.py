"""
Noise Level Ablation Study for Denoising Autoencoder

This script investigates the impact of noise level on DAE performance.

Initial Finding: DAE with noise=0.1 achieved PR-AUC=0.085, WORSE than
standard AE (noise=0.0) with PR-AUC=0.152.

Hypothesis: The noise level (0.1) is too aggressive, causing over-regularization
that smooths out the anomaly signal.

This ablation study tests noise levels: [0.0, 0.01, 0.05, 0.1, 0.2]
to find the optimal balance between regularization and anomaly sensitivity.

Expected outcome: U-shaped curve with optimal noise around 0.01-0.05.
"""

import sys
import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import torch

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from config.config import *
from src.data_utils import (
    load_creditcard_data,
    time_ordered_split,
    standardize_features,
    get_normal_transactions_only,
    print_split_statistics
)

# Import feature columns from config
from config.config import FEATURE_COLUMNS, TRAIN_FRAC, VAL_FRAC, TEST_FRAC
from src.models import DenoisingAutoencoder
from src.training import train_autoencoder, evaluate_reconstruction_error
from src.evaluation import compute_all_metrics, print_evaluation_summary


def main():
    """Main execution function."""

    print("=" * 80)
    print("NOISE LEVEL ABLATION STUDY FOR DENOISING AUTOENCODER")
    print("=" * 80)

    # Print device info
    print(f"\nüñ•Ô∏è  Device: {DEVICE}")
    if DEVICE.type == 'cuda':
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
        print(f"   ‚ö° Training 5 models will take ~10-15 minutes with GPU")
    elif DEVICE.type == 'cpu':
        print(f"   ‚ö†Ô∏è  Running on CPU. Training 5 models will take ~2 hours.")
    print()

    # ==================================================================
    # STEP 1: Load and prepare data
    # ==================================================================
    print("\n" + "=" * 80)
    print("STEP 1: LOADING DATA")
    print("=" * 80)

    # Load data
    df = load_creditcard_data(DATA_PATH)

    # Time-ordered splits
    train_df, val_df, test_df = time_ordered_split(
        df, TRAIN_FRAC, VAL_FRAC, TEST_FRAC
    )
    print_split_statistics(train_df, val_df, test_df)

    # Standardize features
    X_train, y_train, X_val, y_val, X_test, y_test, scaler = standardize_features(
        train_df, val_df, test_df, FEATURE_COLUMNS
    )

    # Extract normal transactions for AE training
    X_train_normal = get_normal_transactions_only(X_train, y_train)
    print(f"\nNormal transactions for AE training: {len(X_train_normal):,}")

    # ==================================================================
    # STEP 2: Test different noise levels
    # ==================================================================
    print("\n" + "=" * 80)
    print("STEP 2: ABLATION STUDY - TESTING NOISE LEVELS")
    print("=" * 80)

    noise_levels = [0.0, 0.01, 0.05, 0.1, 0.2]
    results = []

    print(f"\nTesting noise levels: {noise_levels}")
    print("Note: noise=0.0 is equivalent to standard (non-denoising) autoencoder\n")

    for noise_level in noise_levels:
        print("\n" + "-" * 80)
        print(f"TRAINING WITH NOISE LEVEL: {noise_level}")
        print("-" * 80)

        # Create model
        model = DenoisingAutoencoder(
            input_dim=INPUT_DIM,
            latent_dim=LATENT_DIM,
            hidden_dims=HIDDEN_DIMS,
            noise_level=noise_level
        )

        model_name = f"DAE (noise={noise_level})" if noise_level > 0 else "AE (no noise)"
        print(f"Model: {model_name}")
        print(f"Architecture: {INPUT_DIM} ‚Üí {HIDDEN_DIMS[0]} ‚Üí {HIDDEN_DIMS[1]} ‚Üí {LATENT_DIM} ‚Üí {HIDDEN_DIMS[1]} ‚Üí {HIDDEN_DIMS[0]} ‚Üí {INPUT_DIM}")

        # Train
        training_result = train_autoencoder(
            model=model,
            X_train=X_train_normal,
            X_val=X_val,
            device=DEVICE,
            learning_rate=LEARNING_RATE,
            batch_size=BATCH_SIZE,
            max_epochs=MAX_EPOCHS,
            patience=EARLY_STOPPING_PATIENCE,
            verbose=True
        )

        print(f"\nTraining complete:")
        print(f"  Best epoch: {training_result['best_epoch']}")
        print(f"  Best val loss: {training_result['best_val_loss']:.4f}")
        print(f"  Training time: {training_result['training_time']:.1f}s")

        # Evaluate on validation set
        print("\nValidation set evaluation...")
        val_errors = evaluate_reconstruction_error(
            training_result['model'], X_val, DEVICE, BATCH_SIZE
        )
        val_metrics = compute_all_metrics(y_val, val_errors, model_name)
        print_evaluation_summary(val_metrics, "Validation")

        # Evaluate on test set
        print("\nTest set evaluation...")
        test_errors = evaluate_reconstruction_error(
            training_result['model'], X_test, DEVICE, BATCH_SIZE
        )
        test_metrics = compute_all_metrics(y_test, test_errors, model_name)
        print_evaluation_summary(test_metrics, "Test")

        # Store results
        results.append({
            'noise_level': noise_level,
            'model_name': model_name,
            'best_epoch': training_result['best_epoch'],
            'best_val_loss': training_result['best_val_loss'],
            'training_time': training_result['training_time'],
            'val_roc_auc': val_metrics['roc_auc'],
            'val_pr_auc': val_metrics['pr_auc'],
            'val_recall_at_90p': val_metrics['recall_at_90p'],
            'test_roc_auc': test_metrics['roc_auc'],
            'test_pr_auc': test_metrics['pr_auc'],
            'test_recall_at_90p': test_metrics['recall_at_90p'],
            'test_threshold_at_90p': test_metrics['threshold_at_90p']
        })

        print(f"\n‚úÖ Completed noise={noise_level}")

    # ==================================================================
    # STEP 3: Analyze results
    # ==================================================================
    print("\n" + "=" * 80)
    print("STEP 3: ABLATION STUDY RESULTS")
    print("=" * 80)

    # Create DataFrame
    df_results = pd.DataFrame(results)

    # Display results table
    print("\nTest Set Performance by Noise Level:")
    print("-" * 80)
    print(f"{'Noise Level':<15} {'ROC-AUC':>12} {'PR-AUC':>12} {'Recall@90%P':>15} {'Training Time':>15}")
    print("-" * 80)
    for _, row in df_results.iterrows():
        print(f"{row['noise_level']:<15.2f} {row['test_roc_auc']:>12.4f} {row['test_pr_auc']:>12.4f} {row['test_recall_at_90p']:>15.2f} {row['training_time']:>12.1f}s")
    print("-" * 80)

    # Find best noise level
    best_idx = df_results['test_pr_auc'].idxmax()
    best_noise = df_results.loc[best_idx, 'noise_level']
    best_pr_auc = df_results.loc[best_idx, 'test_pr_auc']

    print(f"\nüèÜ BEST NOISE LEVEL: {best_noise}")
    print(f"   Test PR-AUC: {best_pr_auc:.4f}")

    # Compare to original
    original_idx = df_results[df_results['noise_level'] == 0.1].index[0]
    original_pr_auc = df_results.loc[original_idx, 'test_pr_auc']
    improvement = (best_pr_auc - original_pr_auc) / original_pr_auc * 100

    print(f"\nüìä Comparison to original (noise=0.1):")
    print(f"   Original PR-AUC: {original_pr_auc:.4f}")
    print(f"   Best PR-AUC: {best_pr_auc:.4f}")
    print(f"   Improvement: {improvement:+.1f}%")

    # Compare to standard AE
    ae_idx = df_results[df_results['noise_level'] == 0.0].index[0]
    ae_pr_auc = df_results.loc[ae_idx, 'test_pr_auc']

    if best_noise > 0 and best_pr_auc > ae_pr_auc:
        print(f"\n‚úÖ Optimal denoising (noise={best_noise}) BEATS standard AE!")
        print(f"   Standard AE PR-AUC: {ae_pr_auc:.4f}")
        print(f"   Best DAE PR-AUC: {best_pr_auc:.4f}")
    else:
        print(f"\n‚ö†Ô∏è  Standard AE (noise=0.0) remains best: PR-AUC={ae_pr_auc:.4f}")

    # ==================================================================
    # STEP 4: Visualize results
    # ==================================================================
    print("\n" + "=" * 80)
    print("STEP 4: CREATING VISUALIZATIONS")
    print("=" * 80)

    # Set style
    sns.set_style("whitegrid")
    plt.rcParams['figure.figsize'] = (12, 8)

    # Create figure with subplots
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Noise Level Ablation Study - Denoising Autoencoder', fontsize=16, fontweight='bold')

    # Plot 1: PR-AUC vs Noise Level
    ax1 = axes[0, 0]
    ax1.plot(df_results['noise_level'], df_results['test_pr_auc'], 'o-', linewidth=2, markersize=8, color='#2E86AB')
    ax1.axhline(y=0.152, color='gray', linestyle='--', label='Standard AE (from main results)', alpha=0.7)
    ax1.axvline(x=best_noise, color='red', linestyle='--', alpha=0.5, label=f'Best: {best_noise}')
    ax1.set_xlabel('Noise Level (œÉ)', fontsize=12)
    ax1.set_ylabel('PR-AUC (Test Set)', fontsize=12)
    ax1.set_title('PR-AUC vs Noise Level', fontsize=13, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot 2: ROC-AUC vs Noise Level
    ax2 = axes[0, 1]
    ax2.plot(df_results['noise_level'], df_results['test_roc_auc'], 'o-', linewidth=2, markersize=8, color='#A23B72')
    ax2.axhline(y=0.950, color='gray', linestyle='--', label='Standard AE (from main results)', alpha=0.7)
    ax2.set_xlabel('Noise Level (œÉ)', fontsize=12)
    ax2.set_ylabel('ROC-AUC (Test Set)', fontsize=12)
    ax2.set_title('ROC-AUC vs Noise Level', fontsize=13, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Plot 3: Validation Loss vs Noise Level
    ax3 = axes[1, 0]
    ax3.plot(df_results['noise_level'], df_results['best_val_loss'], 'o-', linewidth=2, markersize=8, color='#F18F01')
    ax3.set_xlabel('Noise Level (œÉ)', fontsize=12)
    ax3.set_ylabel('Best Validation Loss (MSE)', fontsize=12)
    ax3.set_title('Validation Loss vs Noise Level', fontsize=13, fontweight='bold')
    ax3.grid(True, alpha=0.3)

    # Plot 4: Training Time vs Noise Level
    ax4 = axes[1, 1]
    ax4.bar(df_results['noise_level'].astype(str), df_results['training_time'], color='#6A994E', alpha=0.7)
    ax4.set_xlabel('Noise Level (œÉ)', fontsize=12)
    ax4.set_ylabel('Training Time (seconds)', fontsize=12)
    ax4.set_title('Training Time vs Noise Level', fontsize=13, fontweight='bold')
    ax4.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()

    # Save figure
    ablation_plot_path = os.path.join(FIGURES_DIR, 'ablation_noise_levels.png')
    plt.savefig(ablation_plot_path, dpi=300, bbox_inches='tight')
    print(f"Ablation study figure saved to: {ablation_plot_path}")
    plt.close()

    # Create focused PR-AUC plot for report
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(df_results['noise_level'], df_results['test_pr_auc'], 'o-', linewidth=3, markersize=10,
            color='#2E86AB', label='DAE Performance')
    ax.axhline(y=0.152, color='green', linestyle='--', linewidth=2, label='Standard AE (noise=0.0)', alpha=0.7)
    ax.axhline(y=0.085, color='red', linestyle='--', linewidth=2, label='Original DAE (noise=0.1)', alpha=0.7)

    # Mark best point
    ax.plot(best_noise, best_pr_auc, 'r*', markersize=20, label=f'Best: noise={best_noise}')

    ax.set_xlabel('Noise Level (œÉ)', fontsize=14, fontweight='bold')
    ax.set_ylabel('PR-AUC (Test Set)', fontsize=14, fontweight='bold')
    ax.set_title('Impact of Noise Level on Denoising Autoencoder Performance', fontsize=15, fontweight='bold')
    ax.legend(fontsize=11, loc='best')
    ax.grid(True, alpha=0.3)

    # Add annotation
    ax.annotate(f'Peak: {best_pr_auc:.4f}',
                xy=(best_noise, best_pr_auc),
                xytext=(best_noise + 0.03, best_pr_auc - 0.02),
                fontsize=11, fontweight='bold',
                arrowprops=dict(arrowstyle='->', color='red', lw=2))

    plt.tight_layout()

    focused_plot_path = os.path.join(FIGURES_DIR, 'ablation_noise_pr_auc.png')
    plt.savefig(focused_plot_path, dpi=300, bbox_inches='tight')
    print(f"Focused PR-AUC plot saved to: {focused_plot_path}")
    plt.close()

    # ==================================================================
    # STEP 5: Save results
    # ==================================================================
    print("\n" + "=" * 80)
    print("STEP 5: SAVING RESULTS")
    print("=" * 80)

    # Save CSV
    csv_path = os.path.join(TABLES_DIR, 'ablation_noise_results.csv')
    df_results.to_csv(csv_path, index=False)
    print(f"Results CSV saved to: {csv_path}")

    # Save JSON with analysis (convert numpy types to Python native types)
    json_path = os.path.join(TABLES_DIR, 'ablation_noise_analysis.json')

    # Convert all results to JSON-serializable format
    results_serializable = []
    for r in results:
        results_serializable.append({
            'noise_level': float(r['noise_level']),
            'model_name': r['model_name'],
            'best_epoch': int(r['best_epoch']),
            'best_val_loss': float(r['best_val_loss']),
            'training_time': float(r['training_time']),
            'val_roc_auc': float(r['val_roc_auc']),
            'val_pr_auc': float(r['val_pr_auc']),
            'val_recall_at_90p': float(r['val_recall_at_90p']),
            'test_roc_auc': float(r['test_roc_auc']),
            'test_pr_auc': float(r['test_pr_auc']),
            'test_recall_at_90p': float(r['test_recall_at_90p']),
            'test_threshold_at_90p': float(r['test_threshold_at_90p'])
        })

    analysis = {
        'experiment': 'Noise Level Ablation Study',
        'motivation': 'DAE with noise=0.1 performed worse than standard AE (PR-AUC: 0.085 vs 0.152)',
        'hypothesis': 'Lower noise levels will improve performance by reducing over-regularization',
        'noise_levels_tested': [float(n) for n in noise_levels],
        'results': {
            'best_noise_level': float(best_noise),
            'best_pr_auc': float(best_pr_auc),
            'original_noise_level': 0.1,
            'original_pr_auc': float(original_pr_auc),
            'improvement_percent': float(improvement),
            'standard_ae_pr_auc': float(ae_pr_auc)
        },
        'conclusion': (
            f"Optimal noise level: {best_noise} (PR-AUC: {best_pr_auc:.4f}). "
            f"This represents a {improvement:+.1f}% improvement over the original noise=0.1. "
            f"{'DAE with optimal noise outperforms standard AE.' if best_noise > 0 and best_pr_auc > ae_pr_auc else 'Standard AE (no noise) remains the best choice.'}"
        ),
        'all_results': results_serializable
    }

    with open(json_path, 'w') as f:
        json.dump(analysis, f, indent=2)
    print(f"Analysis JSON saved to: {json_path}")

    # Update main results table with best noise level
    best_row = {
        'Model': f'DAE (noise={best_noise}, optimized)',
        'ROC-AUC': float(df_results.loc[best_idx, 'test_roc_auc']),
        'PR-AUC': float(best_pr_auc),
        'Recall@90%P': float(df_results.loc[best_idx, 'test_recall_at_90p']),
        'Threshold@90%P': float(df_results.loc[best_idx, 'test_threshold_at_90p'])
    }

    main_csv_path = os.path.join(TABLES_DIR, 'final_test_results.csv')
    df_main = pd.read_csv(main_csv_path)
    df_main_updated = pd.concat([df_main, pd.DataFrame([best_row])], ignore_index=True)
    df_main_updated.to_csv(main_csv_path, index=False)
    print(f"Best result added to main results table: {main_csv_path}")

    # ==================================================================
    # FINAL SUMMARY
    # ==================================================================
    print("\n" + "=" * 80)
    print("NOISE ABLATION STUDY COMPLETE!")
    print("=" * 80)

    print(f"\nüìä Tested {len(noise_levels)} noise levels: {noise_levels}")
    print(f"\nüèÜ Best configuration:")
    print(f"   Noise level: {best_noise}")
    print(f"   Test PR-AUC: {best_pr_auc:.4f}")
    print(f"   Test ROC-AUC: {df_results.loc[best_idx, 'test_roc_auc']:.4f}")

    print(f"\nüìà Key findings:")
    print(f"   ‚Ä¢ Original DAE (noise=0.1): PR-AUC = {original_pr_auc:.4f}")
    print(f"   ‚Ä¢ Optimized DAE (noise={best_noise}): PR-AUC = {best_pr_auc:.4f}")
    print(f"   ‚Ä¢ Improvement: {improvement:+.1f}%")
    print(f"   ‚Ä¢ Standard AE (noise=0.0): PR-AUC = {ae_pr_auc:.4f}")

    if best_noise == 0.0:
        print(f"\nüí° Conclusion: Standard AE (no denoising) is optimal for this task.")
        print(f"   Denoising regularization consistently degrades anomaly detection performance.")
    else:
        print(f"\nüí° Conclusion: Optimal noise level found at {best_noise}.")
        if best_pr_auc > ae_pr_auc:
            print(f"   Denoising with appropriate noise level improves over standard AE!")
        else:
            print(f"   However, standard AE still performs slightly better.")

    print(f"\nüìÅ Visualizations saved:")
    print(f"   - {ablation_plot_path}")
    print(f"   - {focused_plot_path}")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
